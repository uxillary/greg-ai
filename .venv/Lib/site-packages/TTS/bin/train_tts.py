import os
from dataclasses import dataclass, field

from trainer import Trainer, TrainerArgs

from TTS.config import load_config, register_config
from TTS.tts.datasets import load_tts_samples
from TTS.tts.models import setup_model

def clean_text(text):
    """Remove unwanted characters from text."""
    unwanted_chars = ["\n", "'", '"']  # Include double quotes
    for char in unwanted_chars:
        text = text.replace(char, "")
    return text

@dataclass
class TrainTTSArgs(TrainerArgs):
    config_path: str = field(default=None, metadata={"help": "Path to the config file."})

def main():
    """Run `tts` model training directly by a `config.json` file."""
    # init trainer args
    train_args = TrainTTSArgs()
    parser = train_args.init_argparse(arg_prefix="")

    # override trainer args from comman-line args
    args, config_overrides = parser.parse_known_args()
    train_args.parse_args(args)

    # load config.json and register
    if args.config_path or args.continue_path:
        if args.config_path:
            # init from a file
            config = load_config(args.config_path)
            if len(config_overrides) > 0:
                config.parse_known_args(config_overrides, relaxed_parser=True)
        elif args.continue_path:
            # continue from a prev experiment
            config = load_config(os.path.join(args.continue_path, "config.json"))
            if len(config_overrides) > 0:
                config.parse_known_args(config_overrides, relaxed_parser=True)
        else:
            # init from console args
            from TTS.config.shared_configs import BaseTrainingConfig  # pylint: disable=import-outside-toplevel

            config_base = BaseTrainingConfig()
            config_base.parse_known_args(config_overrides)
            config = register_config(config_base.model)()

    # Explicit language validation
    if config.datasets[0]["language"] != "English":
        raise ValueError("The dataset language must be set to 'English' for this model.")

    # Handle unused multilingual parameters
    if hasattr(config, "TTS") and "is_multi_lingual" in config.TTS:
        print("Ignoring 'is_multi_lingual' for single-language training.")

    # Debugging: Print loaded config
    #print(f"Full loaded config: {config}"),
    #print(f"Loaded config: {config.datasets}")
    print(f"Eval split size: {config.eval_split_size}")

    # Assign default formatter if not set
    for dataset in config.datasets:
        if dataset.formatter == '':
            dataset.formatter = "ljspeech"
        if dataset.path == '':
            dataset.path = "dataset/"
        if dataset.meta_file_train == '':
            dataset.meta_file_train = "metadata.csv"

    # Load training samples
    train_samples, eval_samples = load_tts_samples(
        config.datasets,
        eval_split=True,
        eval_split_max_size=config.eval_split_max_size,
        eval_split_size=0.05,
    )

    # Clean the text in training and evaluation samples
    for sample in train_samples:
        sample["text"] = clean_text(sample["text"])
    for sample in eval_samples:
        sample["text"] = clean_text(sample["text"])

    # init the model from config
    model = setup_model(config, train_samples + eval_samples)

    # init the trainer and ðŸš€
    trainer = Trainer(
        train_args,
        model.config,
        config.output_path,
        model=model,
        train_samples=train_samples,
        eval_samples=eval_samples,
        parse_command_line_args=False,
    )
    trainer.fit()


if __name__ == "__main__":
    main()