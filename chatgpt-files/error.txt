(.venv) PS C:\Users\trigg\Documents\GitHub\greg-ai> python main.py
Starting training...
sys.argv =  ['train_tts', '--config_path', 'aj_config.json', '--output_path', 'output/']
args.config_path: aj_config.json
args.continue_path: 
Dataset config: [BaseDatasetConfig(formatter='ljspeech', dataset_name='', path='dataset/', meta_file_train='metadata.csv', ignored_speakers=None, language='English', phonemizer='English', meta_file_val='metadata_val.csv', meta_file_attn_mask='')]
Loaded dataset language: 'English'
Formatter name received: 'ljspeech'
 | > Found 21 files in C:\Users\trigg\Documents\GitHub\greg-ai\dataset
 > Using model: Tacotron2
 > Setting up Audio Processor...
 | > sample_rate:22050
 | > resample:False
 | > num_mels:80
 | > log_func:np.log10
 | > min_level_db:-100
 | > frame_shift_ms:None
 | > frame_length_ms:None
 | > ref_level_db:20
 | > fft_size:1024
 | > power:1.5
 | > preemphasis:0.0
 | > griffin_lim_iters:60
 | > signal_norm:True
 | > symmetric_norm:True
 | > mel_fmin:0
 | > mel_fmax:None
 | > pitch_fmin:1.0
 | > pitch_fmax:640.0
 | > spec_gain:20.0
 | > stft_pad_mode:reflect
 | > max_norm:4.0
 | > clip_norm:True
 | > do_trim_silence:True
 | > trim_db:45
 | > do_sound_norm:False
 | > do_amp_to_db_linear:True
 | > do_amp_to_db_mel:True
 | > do_rms_norm:False
 | > db_level:None
 | > stats_path:None
 | > base:10
 | > hop_length:256
 | > win_length:1024
 > Training Environment:
 | > Backend: Torch
 | > Mixed precision: False
 | > Precision: float32
 | > Current device: 0
 | > Num. of GPUs: 1
 | > Num. of CPUs: 12
 | > Num. of Torch Threads: 6
 | > Torch seed: 54321
 | > Torch CUDNN: True
 | > Torch CUDNN deterministic: False
 | > Torch CUDNN benchmark: False
 | > Torch TF32 MatMul: False
 > Start Tensorboard: tensorboard --logdir=output\run-February-16-2025_08+11PM-0be4bf2

 > Model has 28274290 parameters

 > EPOCH: 0/100
 --> output\run-February-16-2025_08+11PM-0be4bf2


> DataLoader initialization
| > Tokenizer:
        | > add_blank: False
        | > use_eos_bos: False
        | > use_phonemes: False
| > Number of instances : 21
 | > Preprocessing samples
 | > Max text length: 236
 | > Min text length: 43
 | > Avg text length: 93.23809523809524
 |
 | > Max audio length: 469949.0
 | > Min audio length: 83291.0
 | > Avg audio length: 178938.14285714287
 | > Num. instances discarded samples: 0
 | > Batch group size: 0.

 > TRAINING (2025-02-16 20:12:02) 
C:\Users\trigg\Documents\GitHub\greg-ai\.venv\lib\site-packages\TTS\tts\models\tacotron2.py:337: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.       
  with autocast(enabled=False):  # use float32 for the criterion
C:\Users\trigg\Documents\GitHub\greg-ai\.venv\lib\site-packages\torch\functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\native\TensorShape.cpp:3596.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]

   --> TIME: 2025-02-16 20:12:30 -- STEP: 0/1 -- GLOBAL_STEP: 0
     | > decoder_loss: 2.9830427169799805  (2.9830427169799805)
     | > postnet_loss: 5.1098551750183105  (5.1098551750183105)
     | > stopnet_loss: 0.7042207717895508  (0.7042207717895508)
     | > ga_loss: 0.002848885953426361  (0.002848885953426361)
     | > decoder_diff_spec_loss: 0.16375567018985748  (0.16375567018985748)
     | > postnet_diff_spec_loss: 4.664899826049805  (4.664899826049805)
     | > decoder_ssim_loss: 0.36470460891723633  (0.36470460891723633)
     | > postnet_ssim_loss: 0.3544344902038574  (0.3544344902038574)
     | > loss: 4.12863826751709  (4.12863826751709)
     | > align_error: 0.9947943710722029  (0.9947943710722029)
     | > grad_norm: tensor(3.7019, device='cuda:0')  (tensor(3.7019, device='cuda:0'))
     | > current_lr: 2.5000000000000002e-08
     | > step_time: 26.3806  (26.38063359260559)
     | > loader_time: 1.8292  (1.8291583061218262)

warning: audio amplitude out of range, auto clipped.


> DataLoader initialization
| > Tokenizer:
        | > add_blank: False
        | > use_eos_bos: False
        | > use_phonemes: False
| > Number of instances : 21
 | > Preprocessing samples
 | > Max text length: 236
 | > Min text length: 43
 | > Avg text length: 93.23809523809524
 |
 | > Max audio length: 469949.0
 | > Min audio length: 83291.0
 | > Avg audio length: 178938.14285714287
 | > Num. instances discarded samples: 0
 | > Batch group size: 0.

 > EVALUATION 

 | > Synthesizing test sentences.
   > Decoder stopped with `max_decoder_steps` 50000
