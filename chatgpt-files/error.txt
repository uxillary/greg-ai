 python main.py
Starting training...
args.config_path: config.json
args.continue_path:
Config loaded from file: Tacotron2Config(output_path='output', logger_uri=None, run_name='run', project_name=None, run_description='üê∏Coqui trainer run.', print_step=25, plot_step=100, model_param_stats=False, wandb_entity=None, dashboard_logger='tensorboard', save_on_interrupt=True, log_model_step=None, save_step=10000, save_n_checkpoints=5, save_checkpoints=True, save_all_best=False, save_best_after=0, target_loss=None, print_eval=False, test_delay_epochs=0, run_eval=True, run_eval_steps=None, distributed_backend='nccl', distributed_url='tcp://localhost:54321', mixed_precision=False, precision='fp16', epochs=100, batch_size=32, eval_batch_size=16, grad_clip=5.0, scheduler_after_epoch=True, lr=0.0001, optimizer='RAdam', optimizer_params={'betas': [0.9, 0.998], 'weight_decay': 1e-06}, lr_scheduler='NoamLR', lr_scheduler_params={'warmup_steps': 4000}, use_grad_scaler=False, allow_tf32=False, cudnn_enable=True, cudnn_deterministic=False, cudnn_benchmark=False, training_seed=54321, model='Tacotron2', num_loader_workers=0, num_eval_loader_workers=0, use_noise_augment=False, audio=BaseAudioConfig(fft_size=1024, win_length=1024, hop_length=256, frame_shift_ms=None, frame_length_ms=None, stft_pad_mode='reflect', sample_rate=22050, resample=False, preemphasis=0.0, ref_level_db=20, do_sound_norm=False, log_func='np.log10', do_trim_silence=True, trim_db=45, do_rms_norm=False, db_level=None, power=1.5, griffin_lim_iters=60, num_mels=80, mel_fmin=0.0, mel_fmax=None, spec_gain=20, do_amp_to_db_linear=True, do_amp_to_db_mel=True, pitch_fmax=640.0, pitch_fmin=1.0, signal_norm=True, min_level_db=-100, symmetric_norm=True, max_norm=4.0, clip_norm=True, stats_path=None), use_phonemes=False, phonemizer=None, phoneme_language=None, compute_input_seq_cache=False, text_cleaner=None, enable_eos_bos_chars=False, test_sentences_file='', phoneme_cache_path=None, characters=None, add_blank=False, batch_group_size=0, loss_masking=True, min_audio_len=1, max_audio_len=inf, min_text_len=1, max_text_len=inf, compute_f0=False, compute_energy=False, compute_linear_spec=False, precompute_num_workers=0, start_by_longest=False, shuffle=False, drop_last=False, datasets=[BaseDatasetConfig(formatter='', dataset_name='', path='', meta_file_train='', ignored_speakers=None, language='', phonemizer='', meta_file_val='', meta_file_attn_mask='')], test_sentences=["It took me quite a long time to develop a voice, and now that I have it I'm not going to be silent.", 'Be a voice, not an echo.', "I'm sorry Dave. I'm afraid I can't do that.", "This cake is great. It's so delicious and moist.", 'Prior to November 22, 1963.'], eval_split_max_size=None, eval_split_size=0.01, use_speaker_weighted_sampler=False, speaker_weighted_sampler_alpha=1.0, use_language_weighted_sampler=False, language_weighted_sampler_alpha=1.0, use_length_weighted_sampler=False, length_weighted_sampler_alpha=1.0, use_gst=False, gst=None, gst_style_input=None, use_capacitron_vae=False, capacitron_vae=None, num_speakers=1, num_chars=0, r=2, gradual_training=None, memory_size=-1, prenet_type='original', prenet_dropout=True, prenet_dropout_at_inference=False, stopnet=True, separate_stopnet=True, stopnet_pos_weight=0.2, max_decoder_steps=50000, encoder_in_features=512, decoder_in_features=512, decoder_output_dim=80, out_channels=80, attention_type='original', attention_heads=None, attention_norm='sigmoid', attention_win=False, windowing=False, use_forward_attn=False, forward_attn_mask=False, transition_agent=False, location_attn=True, bidirectional_decoder=False, double_decoder_consistency=False, ddc_r=6, speakers_file=None, use_speaker_embedding=False, speaker_embedding_dim=512, use_d_vector_file=False, d_vector_file=False, d_vector_dim=None, seq_len_norm=False, decoder_loss_alpha=0.25, postnet_loss_alpha=0.25, postnet_diff_spec_alpha=0.25, decoder_diff_spec_alpha=0.25, decoder_ssim_alpha=0.25, postnet_ssim_alpha=0.25, ga_alpha=5.0)
Dataset config: [BaseDatasetConfig(formatter='', dataset_name='', path='', meta_file_train='', ignored_speakers=None, language='', phonemizer='', meta_file_val='', meta_file_attn_mask='')]
Traceback (most recent call last):
  File "C:\Users\trigg\Documents\GitHub\greg-ai\main.py", line 75, in <module>
    train()
  File "C:\Users\trigg\Documents\GitHub\greg-ai\main.py", line 51, in train
    train_tts_main()
  File "C:\Users\trigg\Documents\GitHub\greg-ai\.venv\lib\site-packages\TTS\bin\train_tts.py", line 52, in main
    raise ValueError("The 'language' field is missing or empty in the dataset configuration.")
ValueError: The 'language' field is missing or empty in the dataset configuration.