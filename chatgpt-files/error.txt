(.venv) PS C:\Users\trigg\Documents\GitHub\greg-ai> python main.py
Testing pre-trained model...
 > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.
 > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.
 > Using model: Tacotron2
 > Setting up Audio Processor...
 | > sample_rate:22050
 | > resample:False
 | > num_mels:80
 | > log_func:np.log
 | > min_level_db:-100
 | > frame_shift_ms:None
 | > frame_length_ms:None
 | > ref_level_db:20
 | > fft_size:1024
 | > power:1.5
 | > preemphasis:0.0
 | > griffin_lim_iters:60
 | > signal_norm:False
 | > symmetric_norm:True
 | > mel_fmin:0
 | > mel_fmax:8000.0
 | > pitch_fmin:1.0
 | > pitch_fmax:640.0
 | > spec_gain:1.0
 | > stft_pad_mode:reflect
 | > max_norm:4.0
 | > clip_norm:True
 | > do_trim_silence:True
 | > trim_db:60
 | > do_sound_norm:False
 | > do_amp_to_db_linear:True
 | > do_amp_to_db_mel:True
 | > do_rms_norm:False
 | > db_level:None
 | > stats_path:None
 | > base:2.718281828459045
 | > hop_length:256
 | > win_length:1024
C:\Users\trigg\Documents\GitHub\greg-ai\.venv\lib\site-packages\TTS\utils\io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=map_location, **kwargs)
 > Model's reduction rate `r` is set to: 1
 > Vocoder Model: hifigan
 > Setting up Audio Processor...
 | > sample_rate:22050
 | > resample:False
 | > num_mels:80
 | > log_func:np.log
 | > min_level_db:-100
 | > frame_shift_ms:None
 | > frame_length_ms:None
 | > ref_level_db:20
 | > fft_size:1024
 | > power:1.5
 | > preemphasis:0.0
 | > griffin_lim_iters:60
 | > signal_norm:False
 | > symmetric_norm:True
 | > mel_fmin:0
 | > mel_fmax:8000.0
 | > pitch_fmin:1.0
 | > pitch_fmax:640.0
 | > spec_gain:1.0
 | > stft_pad_mode:reflect
 | > max_norm:4.0
 | > clip_norm:True
 | > do_trim_silence:False
 | > trim_db:60
 | > do_sound_norm:False
 | > do_amp_to_db_linear:True
 | > do_amp_to_db_mel:True
 | > do_rms_norm:False
 | > db_level:None
 | > stats_path:None
 | > base:2.718281828459045
 | > hop_length:256
 | > win_length:1024
 > Generator Model: hifigan_generator
 > Discriminator Model: hifigan_discriminator
Removing weight norm...
 > Text splitted to sentences.
['Hello, this is a test of text-to-speech synthesis.']
 > Processing time: 1.4753334522247314
 > Real-time factor: 0.36094335413584383
Test audio generated: output/test-output.wav
Starting fine-tuning...
Eval split size: 0.01
Formatter name received: 'ljspeech'
 | > Found 21 files in C:\Users\trigg\Documents\GitHub\greg-ai\dataset
 > Using model: Tacotron2
 > Setting up Audio Processor...
 | > sample_rate:22050
 | > resample:False
 | > num_mels:80
 | > log_func:np.log10
 | > min_level_db:-100
 | > frame_shift_ms:None
 | > frame_length_ms:None
 | > ref_level_db:20
 | > fft_size:1024
 | > power:1.5
 | > preemphasis:0.0
 | > griffin_lim_iters:60
 | > signal_norm:True
 | > symmetric_norm:True
 | > mel_fmin:0
 | > mel_fmax:None
 | > pitch_fmin:1.0
 | > pitch_fmax:640.0
 | > spec_gain:20.0
 | > stft_pad_mode:reflect
 | > max_norm:4.0
 | > clip_norm:True
 | > do_trim_silence:True
 | > trim_db:45
 | > do_sound_norm:False
 | > do_amp_to_db_linear:True
 | > do_amp_to_db_mel:True
 | > do_rms_norm:False
 | > db_level:None
 | > stats_path:None
 | > base:10
 | > hop_length:256
 | > win_length:1024
 > Training Environment:
 | > Backend: Torch
 | > Mixed precision: False
 | > Precision: float32
 | > Current device: 0
 | > Num. of GPUs: 1
 | > Num. of CPUs: 12
 | > Num. of Torch Threads: 6
 | > Torch seed: 54321
 | > Torch CUDNN: True
 | > Torch CUDNN deterministic: False
 | > Torch CUDNN benchmark: False
 | > Torch TF32 MatMul: False
 > Start Tensorboard: tensorboard --logdir=output\run-December-23-2024_02+00PM-8afc193

 > Model has 28274290 parameters

 > EPOCH: 0/1000
 --> output\run-December-23-2024_02+00PM-8afc193


> DataLoader initialization
| > Tokenizer:
        | > add_blank: False
        | > use_eos_bos: False
        | > use_phonemes: False
| > Number of instances : 20
 | > Preprocessing samples
 | > Max text length: 237
 | > Min text length: 42
 | > Avg text length: 85.55
 |
 | > Max audio length: 583958.0
 | > Min audio length: 48918.0
 | > Avg audio length: 189955.4
 | > Num. instances discarded samples: 0
 | > Batch group size: 0.

 > TRAINING (2024-12-23 14:00:43) 
There was enough material, for a new album.

 [!] Character '\n' not found in the vocabulary. Discarding it.
Abramoff's lobbying team would prepare questions and "factual backup" for friendly lawmakers.

 [!] Character '"' not found in the vocabulary. Discarding it.
C:\Users\trigg\Documents\GitHub\greg-ai\.venv\lib\site-packages\TTS\tts\models\tacotron2.py:337: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=False):  # use float32 for the criterion
C:\Users\trigg\Documents\GitHub\greg-ai\.venv\lib\site-packages\torch\functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\native\TensorShape.cpp:3596.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]

   --> TIME: 2024-12-23 14:01:10 -- STEP: 0/1 -- GLOBAL_STEP: 0
     | > decoder_loss: 7.282797336578369  (7.282797336578369)
     | > postnet_loss: 9.550230026245117  (9.550230026245117)
     | > stopnet_loss: 0.6421263217926025  (0.6421263217926025)
     | > ga_loss: 0.002910495037212968  (0.002910495037212968)
     | > decoder_diff_spec_loss: 0.16255341470241547  (0.16255341470241547)
     | > postnet_diff_spec_loss: 4.830276966094971  (4.830276966094971)
     | > decoder_ssim_loss: 0.3038979172706604  (0.3038979172706604)
     | > postnet_ssim_loss: 0.29875612258911133  (0.29875612258911133)
     | > loss: 6.263806343078613  (6.263806343078613)
     | > align_error: 0.9935018406249583  (0.9935018406249583)
     | > grad_norm: tensor(5.5308, device='cuda:0')  (tensor(5.5308, device='cuda:0'))
     | > current_lr: 2.5000000000000002e-08
     | > step_time: 26.1072  (26.10723376274109)
     | > loader_time: 1.4191  (1.4190673828125)

warning: audio amplitude out of range, auto clipped.


> DataLoader initialization
| > Tokenizer:
        | > add_blank: False
        | > use_eos_bos: False
        | > use_phonemes: False
        | > 2 not found characters:
        | >

        | > "
| > Number of instances : 1
 | > Preprocessing samples
 | > Max text length: 71
 | > Min text length: 71
 | > Avg text length: 71.0
 |
 | > Max audio length: 157796.0
 | > Min audio length: 157796.0
 | > Avg audio length: 157796.0
 | > Num. instances discarded samples: 0
 | > Batch group size: 0.

 > EVALUATION 

 | > Synthesizing test sentences.
   > Decoder stopped with `max_decoder_steps` 10000
   > Decoder stopped with `max_decoder_steps` 10000