# Gregg ğŸ—£ï¸ğŸ‡¬ğŸ‡§  
**Scottish AI Voice Model â€” TTS Fine-tuning Project**

Welcome to **Gregg**, a voice cloning project using AI to train a custom Scottish accent voice (nicknamed â€œGregâ€). This repository uses **Tacotron2** for spectrogram generation and **HiFi-GAN** for waveform synthesis to create high-quality, expressive speech from text.

---

## ğŸ¯ Project Goals

- Train a natural-sounding voice model for â€œGregâ€ (Scottish accent)
- Use open-source tools for fine-tuning on a small custom dataset
- Experiment with phoneme settings, audio quality, and inference improvements

---

## ğŸ› ï¸ Core Features

- âœ… **Tacotron2 + HiFi-GAN**: Neural TTS stack for clear speech synthesis  
- âœ… **LJSpeech-compatible Formatting**: Flexible with `metadata.csv`  
- âœ… **Custom Voice Training**: Easily fine-tune using your own recordings  
- âœ… **Configurable Output**: Adjust all model, training, and audio parameters via `config.json`  
- âœ… **Test Sentences**: Quickly generate inference output from predefined sentences  
- âœ… **Supports English Phonemizer**: For improved pronunciation control  

---

## ğŸ“¦ Requirements

- Python 3.7+
- PyTorch with GPU support recommended
- FFmpeg installed and accessible in PATH

Install dependencies:

```bash
pip install -r requirements.txt
```

---

## âš™ï¸ Configuration

Example `config.json` snippet:

```json
{
  "model": "Tacotron2",
  "generator_model": "HiFi-GAN",
  "audio_config": {
    "sample_rate": 22050,
    "fft_size": 1024,
    "hop_length": 256
  },
  "training_config": {
    "epochs": 100,
    "batch_size": 16,
    "learning_rate": 0.001
  },
  "datasets": [
    {
      "formatter": "ljspeech",
      "path": "dataset/",
      "meta_file_train": "metadata.csv",
      "language": "English",
      "phonemizer": "English"
    }
  ]
}
```

ğŸ’¡ **Important**: Make sure the `"language"` is explicitly set to `"English"` â€” the model will error out otherwise.

---

## ğŸ§ª Usage

### ğŸ”Š Generate Speech

```bash
python main.py
```

This will generate a sample file like:

```
output/test-output.wav
```

---

### ğŸ§¬ Train / Fine-Tune Model

```bash
python train_tts.py --config_path config.json --output_path output/
```

Training progress is saved to:

```
output/checkpoints/
output/logs/
```

You can resume training with:

```bash
python train_tts.py --config_path config.json --continue_path output/
```

---

## ğŸ“ Project Structure

```
greg-ai/
â”œâ”€â”€ config.json           # Main configuration
â”œâ”€â”€ main.py               # Synthesis entry point
â”œâ”€â”€ train_tts.py          # Training script
â”œâ”€â”€ dataset/              # Custom audio and metadata
â”‚   â”œâ”€â”€ metadata.csv
â”‚   â””â”€â”€ wavs/
â”œâ”€â”€ output/               # Checkpoints, logs, generated audio
â”œâ”€â”€ .venv/                # Python virtual environment
```

---

## ğŸ—ƒï¸ Dataset Format

The dataset folder should follow this format:

```
dataset/
â”œâ”€â”€ metadata.csv    # Format: filename|transcript
â”œâ”€â”€ wavs/
â”‚   â”œâ”€â”€ clip1.wav
â”‚   â”œâ”€â”€ clip2.wav
```

- All audio files must be mono WAV format
- Use a sample rate of **22050 Hz**
- Match filenames exactly to `metadata.csv` entries

---

## ğŸ Troubleshooting

### âŒ `ValueError: The dataset language must be set to 'English'`

Ensure that `"language": "English"` is set in the config and dataset section. Also make sure the phonemizer is valid for English or left out if unused.

---

## ğŸ™Œ Credits

- ğŸ—£ï¸ [Tacotron2](https://arxiv.org/abs/1712.05884)  
- ğŸµ [HiFi-GAN](https://arxiv.org/abs/2010.05646)  
- ğŸ¤ [LJSpeech Dataset](https://keithito.com/LJ-Speech-Dataset/)  
- ğŸ§  [Coqui TTS](https://github.com/coqui-ai/TTS) â€” the library powering this repo

---

## ğŸ“„ License

MIT â€” free to use, modify, and share. See [LICENSE](./LICENSE) file for details.

---

## ğŸ’¬ Contact

Built by **Adam** â€” [adam@ajstudios.dev](mailto:adam@ajstudios.dev)  
Project repo: [github.com/uxillary/greg-ai](https://github.com/uxillary/greg-ai)

---

## ğŸš§ Future Plans

- XTTS v2 support for multi-speaker synthesis  
- Dataset augmentation via phoneme control  
- Real-time inference UI using Streamlit or Gradio  
- Voice personality tuning and expression embedding
